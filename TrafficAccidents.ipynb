{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " US Accident Exploratory Data Analysis \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import opendatasets as od\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "#To download the dataset via URL the following two lines of code will download into a local directory\n",
    "# opendatasets package is needed for this -- pip install opendatasets --upgrade -- run this in your preferred env \n",
    "#You will need a user name and API key from Kaggle for this to work as well. Your API token can be generated from the MyAccount page\n",
    "\n",
    "# download_url = 'https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents'\n",
    "# od.download(download_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the file as a variable for later use\n",
    "data_filename = './us-accidents/US_Accidents_Dec21_updated.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Cleaning TODO \n",
    "1. Load the file uing Pandas\n",
    "2. Look at and understand some information about the data & the columns\n",
    "3. Fix any missing or incorrect values\n",
    "4. Discuss that New York is not contained Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get an idea of how many columns there are and some of the data they have inside of them\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the stats of the data to create some questions about the data.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask & Answer Questions\n",
    "\n",
    "1. Are there more accidents in warmer or colder areas?\n",
    "2. Which states have the highest number of accidents - Per capita?\n",
    "3. How frequently does precipitaion appear in accidents\n",
    "4. Among the top 100 cities in number of accidents, which states do they belong to most frequently.\n",
    "5. What time of the day are accidents frequently occouring \n",
    "6. Which Days of the week have the most accidents\n",
    "7. Which Months have the most accidents\n",
    "8. What is the trend of accidents Year over Year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the number of numeric columns \n",
    "numerics = ['int16','int32','int64','float16','float32','float64']\n",
    "numeric_df = df.select_dtypes(include=numerics)\n",
    "print(len(df.columns))\n",
    "print(len(numeric_df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of missing values per column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for NA values, if the values is PRESENT in the df it will return FALSE, if it is empty, it will return TRUE\n",
    "#To count these, simply run the sum function\n",
    "\n",
    "list_of_sum_na = df.isna().sum().sort_values(ascending=False)\n",
    "missing_percentage_of_na = list_of_sum_na / len(df)\n",
    "missing_percentage_of_na_zeropulled = missing_percentage_of_na[missing_percentage_of_na != 0]\n",
    "\n",
    "\n",
    "print(list_of_sum_na)\n",
    "missing_percentage_of_na_zeropulled.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A higher number on the bar indicates a higher missing percentage so Street is not frequently missing while number is frequently missing a value\n",
    "# If it is misisng more than half of the time from the data it will not be very helpful for the analysis\n",
    "# I am going to go ahead and delete the columns with less relevance, to run this fresh you will need to un comment\n",
    "\n",
    "# del df['Number']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis and Visualization \n",
    "\n",
    "Columns to analyze :\n",
    "1. City\n",
    "2. Start Time\n",
    "3. Start Lat, Start Long\n",
    "4. Temperature \n",
    "5. Weather Condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.City\n",
    "unique_cities = df.City.unique()\n",
    "print(len(unique_cities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_by_accident = df.City.value_counts()\n",
    "#Check for the unique occurances for accident per city | Top 20\n",
    "cities_by_accident[:20]\n",
    "#I noticed that New york is not in here, which seems a bit strange to me\n",
    "#\"New York\" in df.City\n",
    "#Return False\n",
    "#\"NY\" in df.State\n",
    "#Return False\n",
    "#Data is not being collected on NY for whatever reason\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_by_accident[:20].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the distrubution of accidents per city using a distplot \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.distplot(cities_by_accident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This distrubution plot shows us that most of cities don't really have many accidents, but the ones that do have more than the norm has exceedingly more than the norm. It would be helpful to seperate these \n",
    "\n",
    "high_accident_cities = cities_by_accident[cities_by_accident >= 1000]\n",
    "low_accident_cities = cities_by_accident[cities_by_accident < 1000]\n",
    "\n",
    "print(len(high_accident_cities))\n",
    "print(len(low_accident_cities))\n",
    "\n",
    "# The percentage of accidents per city \n",
    "\n",
    "percentage_of_high_from_whole = len(high_accident_cities) / len(cities_by_accident)\n",
    "print(percentage_of_high_from_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(high_accident_cities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(high_accident_cities, log_scale = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(low_accident_cities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(low_accident_cities, log_scale = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems a little strange that the log shows that the data is a little scewed. I am going to check the values for 1, because there may be some problem with the data\n",
    "values_of_one = cities_by_accident[cities_by_accident == 1]\n",
    "print(values_of_one)\n",
    "# 1110 values only have one accident logged which seems like it might not be totally relevant for high level analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of accident time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.Start_Time = pd.to_datetime(df.Start_Time)\n",
    "sns.distplot(df.Start_Time.dt.month, bins = 12,kde=False, norm_hist=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to give some representation to the actual count of accidents that have been happening on a monthly basis I will draw another graph\n",
    "df.Start_Time.dt.month.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Although there is some missing data for January, I think that this trend is fairly accurate\n",
    "2. Traveling holidays (Thanksgiving & Chrismtas) tend to affect the month wise trend of accidnets\n",
    "3. The trend starts moving up starting in September (Labor Day) and then continues moving up\n",
    "4. I would like to see the sources so that I could compare distrubutions. External source may be needed.\n",
    "5. The bar graph shows a clear trend by number.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see which hours of the day have the most accidents\n",
    "df.Start_Time\n",
    "# The data is in a strange format. I will format it to be in DateTime\n",
    "df.Start_Time = pd.to_datetime(df.Start_Time)\n",
    "#Because Start_Time is a time stamp we will need to break it down into peices for it to be usable \n",
    "sns.distplot(df.Start_Time.dt.hour, bins = 24,kde=False, norm_hist=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- We can see that a higher percentage of accidents happen between 3pm and 6pm | Assumptions can be made that it is due to to people in a hurry leaving work or picking up kids from school\n",
    "-- The next highest percentage is between 6am and 9pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see which day of the week has the most accidents\n",
    "sns.distplot(df.Start_Time.dt.day_of_week, bins = 7,kde=False, norm_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- It is evenly distributed during the weekdays with a slight increase on Friday.\n",
    "-- The weekend however has a steep decline in accidents.\n",
    "-- The assumption is that less people are traveling during the weekend, as they don't have to go to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly Analysis per day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sunday Distrubution \n",
    "sunday_accidents = df.Start_Time[df.Start_Time.dt.day_of_week == 6]\n",
    "sns.distplot(sunday_accidents.dt.hour, kde=False, norm_hist=True, bins = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monday Distrubution \n",
    "monday_accidents = df.Start_Time[df.Start_Time.dt.day_of_week == 0]\n",
    "sns.distplot(monday_accidents.dt.hour, kde=False, norm_hist=True, bins = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuesday Distrubution \n",
    "tuesday_accidents = df.Start_Time[df.Start_Time.dt.day_of_week == 1]\n",
    "sns.distplot(tuesday_accidents.dt.hour, kde=False, norm_hist=True, bins = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wednesday Distrubution \n",
    "wednesday_accidents = df.Start_Time[df.Start_Time.dt.day_of_week == 2]\n",
    "sns.distplot(wednesday_accidents.dt.hour, kde=False, norm_hist=True, bins = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thursday Distrubution \n",
    "thursday_accidents = df.Start_Time[df.Start_Time.dt.day_of_week == 3]\n",
    "sns.distplot(thursday_accidents.dt.hour, kde=False, norm_hist=True, bins = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Friday Distrubution \n",
    "friday_accidents = df.Start_Time[df.Start_Time.dt.day_of_week == 4]\n",
    "sns.distplot(friday_accidents.dt.hour, kde=False, norm_hist=True, bins = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saturday Distrubution \n",
    "saturday_accidents = df.Start_Time[df.Start_Time.dt.day_of_week == 5]\n",
    "sns.distplot(saturday_accidents.dt.hour, kde=False, norm_hist=True, bins = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of geographic positioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Start_Lat, df.Start_Lng\n",
    "sns.scatterplot(x = df.Start_Lng, y =  df.Start_Lat, size= .001)\n",
    "# Generally speaking there are very few parts of the US that DON'T experience traffic accidents\n",
    "# I made the points smaller so that you could see the density a little better\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lng_list = list(df.Start_Lng)\n",
    "lat_list = list(df.Start_Lat)\n",
    "paired_list = list(zip(lng_list,lat_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map()\n",
    "folium.plugins.HeatMap(zip(list(df.Start_Lat), list(df.Start_Lng))).add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A heat map demonstrates this futher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusion \n",
    "\n",
    "Insights:\n",
    "- No data about from New York \n",
    "- Low percent of cities have more than 1000 yearly accidents (Around 4 percent )\n",
    "- Over 1100 Cities have reported only 1 accident\n",
    "- The number of accidents per city decreases exponentially \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8640a4b2df460c6d26010c6a8a91f87d721050827e55e577e37d45854dce3b5a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('minimal_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
